{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting meegkit\n",
      "  Downloading meegkit-0.1.7-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from meegkit) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from meegkit) (1.14.0)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from meegkit) (3.9.1)\n",
      "Collecting scikit-learn (from meegkit)\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from meegkit) (2.2.2)\n",
      "Collecting joblib (from meegkit)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from meegkit) (4.66.5)\n",
      "Collecting statsmodels (from meegkit)\n",
      "  Downloading statsmodels-0.14.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyriemann>=0.2.7 (from meegkit)\n",
      "  Downloading pyriemann-0.6-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->meegkit)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from matplotlib->meegkit) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from matplotlib->meegkit) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from matplotlib->meegkit) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from matplotlib->meegkit) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from matplotlib->meegkit) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from matplotlib->meegkit) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from matplotlib->meegkit) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from matplotlib->meegkit) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from pandas->meegkit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from pandas->meegkit) (2024.1)\n",
      "Collecting patsy>=0.5.6 (from statsmodels->meegkit)\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/master/lib/python3.11/site-packages (from patsy>=0.5.6->statsmodels->meegkit) (1.16.0)\n",
      "Downloading meegkit-0.1.7-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m701.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyriemann-0.6-py2.py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.5.1-cp311-cp311-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading statsmodels-0.14.2-cp311-cp311-macosx_10_9_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, patsy, joblib, scikit-learn, statsmodels, pyriemann, meegkit\n",
      "Successfully installed joblib-1.4.2 meegkit-0.1.7 patsy-0.5.6 pyriemann-0.6 scikit-learn-1.5.1 statsmodels-0.14.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install meegkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import torch\n",
    "\n",
    "from utils import get_args, get_mne_info\n",
    "\n",
    "import mne\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from preprocessing.utils import split_raw, get_unannotated_raw, split_raw_annotations\n",
    "from preprocessing.methods import PreprocessMethods\n",
    "\n",
    "# Import typing\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "from preprocessing.pipeline import BasePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw(args):\n",
    "    data = torch.load(os.path.join(args.dataset_dir, \"EEG-ImageNet_1.pth\"))\n",
    "\n",
    "    eeg_data_list = []\n",
    "    labels = []\n",
    "\n",
    "    descriptions = data['labels']\n",
    "\n",
    "    for event in data['dataset']:\n",
    "        eeg_data_list.append(event['eeg_data'].numpy())  # Convert tensors to numpy arrays\n",
    "        labels.append(event['label']) # data['labels'].index(event['label']))  # Convert labels to ints and store them in a list\n",
    "\n",
    "    eeg_data = np.concatenate(eeg_data_list, axis=1)\n",
    "\n",
    "    info = get_mne_info()\n",
    "\n",
    "    # Create RawArray object\n",
    "    raw = mne.io.RawArray(eeg_data, info)\n",
    "\n",
    "    annotations = []\n",
    "    onset = 0\n",
    "    for label, event in zip(labels, eeg_data_list):\n",
    "        duration = event.shape[1] / info.get('sfreq')  # Calculate the duration of each event\n",
    "        annotations.append([onset, duration, str(label)])  # Onset, Duration, Label\n",
    "        onset += duration\n",
    "\n",
    "    # Create MNE Annotations object\n",
    "    annotations = mne.Annotations(onset=[ann[0] for ann in annotations],\n",
    "                                duration=[ann[1] for ann in annotations],\n",
    "                                description=[ann[2] for ann in annotations])\n",
    "\n",
    "    # Set annotations to the raw object\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    return raw, descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DownstreamPipeline(BasePipeline):\n",
    "    def __init__(self, args, descriptions: List[str], tmin: float = -0.5, tlen: float = 5.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.descriptions = descriptions\n",
    "        self.description_map = {label: i for i, label in enumerate(descriptions)}\n",
    "        self.tmin, self.tlen = tmin, tlen\n",
    "\n",
    "        self.args = args\n",
    "        \n",
    "    def __call__(self, src_paths: List[str]) -> Tuple[List[mne.io.Raw], List[Tuple[float, float]], List[int]]:\n",
    "        return self.run(src_paths)\n",
    "    \n",
    "    def run(self):\n",
    "        logging.debug(\"Loading EDF files...\")\n",
    "        # src_paths = [Path(src_path) for src_path in src_paths]\n",
    "\n",
    "        raws = []\n",
    "        \n",
    "        logging.debug(\"Splitting raws...\")   \n",
    "        for i in range(0,8):\n",
    "            try:\n",
    "                raw_orig = get_raw(get_args(subject = i)) # mne.io.read_raw_edf(src_path, preload=True, verbose=False)\n",
    "                \n",
    "                # Rename channels with channel_rename\n",
    "                if self.channels_rename is not None:\n",
    "                    raw_orig.rename_channels(self.channels_rename)\n",
    "                    #logging.info(f\"File: {src_paths[i].stem}.\\tRenamed channels: {self.channels_rename}.\")\n",
    "                           \n",
    "                self._to_standard_names(raw_orig)\n",
    "                drop_chs = self._set_montage(raw_orig)\n",
    "                #logging.info(f\"File: {src_paths[i].stem}.\\tDropped {len(drop_chs)} channels when setting montage: {drop_chs}.\")\n",
    "            except Exception as e:\n",
    "                #logging.error(f\"Dropping file: {src_path.stem}.\\tError: {e}\")\n",
    "                continue\n",
    "\n",
    "            raws.append(raw_orig)\n",
    "            \n",
    "        total_windows = len(raws)\n",
    "        logging.debug(f\"Total files: {total_windows}\")\n",
    "                       \n",
    "        for i, raw in enumerate(raws):\n",
    "            filename = f\"subject {i}\" # src_paths[i]\n",
    "            \n",
    "            try:\n",
    "                raws[i] = self.run_single(raw, filename)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"File: {filename}.\\tError: {e}\")\n",
    "                raws[i] = None\n",
    "                \n",
    "            # Log progress every N windows\n",
    "            if (i + 1) % 10 == 0:\n",
    "                logging.debug(f\"Processed {i + 1}/{total_windows} files.\")\n",
    "     \n",
    "        raw_windows = []\n",
    "        times = []\n",
    "        indices = []\n",
    "        descriptions = []\n",
    "        \n",
    "        for i, raw in enumerate(raws):\n",
    "            windows, time_slices, descri = split_raw_annotations(raw, labels = self.descriptions, tmin=self.tmin,\n",
    "                                                                 tlen=self.tlen, verbose=False)\n",
    "            raw_windows.extend(windows)\n",
    "            times.extend(time_slices)\n",
    "            descriptions.extend(descri)\n",
    "            indices.extend([i] * len(windows))\n",
    "            \n",
    "        labels = [self.description_map[description] for description in descriptions]\n",
    "        \n",
    "        assert len(raw_windows) == len(times) == len(indices) == len(labels)\n",
    "        \n",
    "        return raw_windows, times, indices, labels\n",
    "    \n",
    "    def run_single(self, raw, filename) -> Optional[mne.io.Raw]:\n",
    "        window_info_str = f\"File: {filename}.\"\n",
    "        \n",
    "        self._remove_line_noise(raw)\n",
    "        \n",
    "        raw_unannotated = raw #get_unannotated_raw(raw, resting_state=['T0'])\n",
    "        bad_chs = self._find_bad_channels(raw_unannotated)\n",
    "        logging.info(f\"{window_info_str}\\tFound {len(bad_chs)} bad channels: {bad_chs}.\")\n",
    "        \n",
    "        # Drop bad channels\n",
    "        raw.drop_channels(bad_chs)\n",
    "        \n",
    "        self._filter(raw)    \n",
    "        self._average_reference(raw)\n",
    "                \n",
    "        if self.do_ica:\n",
    "            excluded_idxs, labels, y_proba = self._ica_clean(raw)\n",
    "            logging.info(f\"{window_info_str}\\tExcluding {len(excluded_idxs)} components: {excluded_idxs}.\")\n",
    "            logging.info(f\"{window_info_str}\\tLabels: {labels}.\")\n",
    "            logging.info(f\"{window_info_str}\\tProbabilities: {[round(prob, 2) for prob in y_proba]}.\")\n",
    "            \n",
    "            raw_unannotated = raw #get_unannotated_raw(raw, resting_state=['T0'])\n",
    "            bad_chs = self._find_bad_channels(raw_unannotated)\n",
    "            logging.info(f\"{window_info_str}\\tFound {len(bad_chs)} bad channels: {bad_chs}.\")\n",
    "            \n",
    "            # Drop bad channels\n",
    "            raw.drop_channels(bad_chs)\n",
    "\n",
    "        missing_chs = self._interpolate_missing(raw)\n",
    "        logging.info(f\"{window_info_str}\\tIntepolating {len(missing_chs)} channels: {missing_chs}.\")\n",
    "        \n",
    "        extra_chs = self._drop_extra_and_reorder(raw)\n",
    "        logging.info(f\"{window_info_str}\\tRemoving {len(extra_chs)} extra channels: {extra_chs}.\")\n",
    "        \n",
    "        self._interpolate_nearest(raw)        \n",
    "        return raw\n",
    "    \n",
    "    def _find_bad_channels(self, raw: mne.io.Raw, drop=True):       \n",
    "        return PreprocessMethods.find_bad_channels(raw, ransac = self.ransac, drop = False)\n",
    "    \n",
    "class DownstreamPipelineBENDR(DownstreamPipeline):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def _zero_missing(self, raw: mne.io.Raw):\n",
    "        return PreprocessMethods.zero_missing(raw, self.chs, self.montage)\n",
    "    \n",
    "    def run_single(self, raw, filename) -> Optional[mne.io.Raw]:\n",
    "        window_info_str = f\"File: {filename}.\"\n",
    "        \n",
    "        missing_chs = self._zero_missing(raw)\n",
    "        logging.info(f\"{window_info_str}\\Zeroing {len(missing_chs)} channels: {missing_chs}.\")\n",
    "        \n",
    "        extra_chs = self._drop_extra_and_reorder(raw)\n",
    "        logging.info(f\"{window_info_str}\\tRemoving {len(extra_chs)} extra channels: {extra_chs}.\")\n",
    "        \n",
    "        self._interpolate_nearest(raw)        \n",
    "        return raw\n",
    "    \n",
    "    def _find_bad_channels(self, raw: mne.io.Raw, drop=True):       \n",
    "        return PreprocessMethods.find_bad_channels(raw, ransac = self.ransac, drop = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=62, n_times=16006950\n",
      "    Range : 0 ... 16006949 =      0.000 ... 16006.949 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "raw, descriptions = get_raw(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "DownstreamPipeline(args, descriptions).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
